{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import minmax_scale as mms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,name):\n",
    "    csv_path = os.path.join(path, name)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wine dataset ...\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/UX310UQ/Documents/Maestria_I/RedesNeurais/Redes neurais/RedesNeurais\"\n",
    "name = \"winequality-red.csv\"\n",
    "data = load_data(path,name)\n",
    "print(\"Loading wine dataset ...\")\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert Categorical Output to One Hot Vector\n"
     ]
    }
   ],
   "source": [
    "#Convert Categorical Output to One Hot Vector: [100-010-001]\n",
    "print(\"Convert Categorical Output to One Hot Vector\")\n",
    "Y = data[\"category\"]\n",
    "Y = Y.values.reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(Y)\n",
    "Y = enc.transform(Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing inputs droping Labels and droping indexs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "X = X.drop(\"Unnamed: 0\", axis = 1)\n",
    "X = X.drop(\"category\", axis = 1)\n",
    "print(\"Preparing inputs droping Labels and droping indexs\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traind and Test datasets Stratify Splitting\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=0, stratify=Y)\n",
    "print(\"Traind and Test datasets Stratify Splitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Shapes after Splitting\n",
      "(1199, 11)\n",
      "(400, 11)\n",
      "(1199, 3)\n",
      "(400, 3)\n",
      "Train and Test Shapes after Scalling : Values between 0 and 1\n",
      "(1199, 11)\n",
      "(400, 11)\n",
      "(1199, 3)\n",
      "(400, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and Test Shapes after Splitting\")\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(\"Train and Test Shapes after Scalling : Values between 0 and 1\")\n",
    "x_train = mms(x_train)\n",
    "x_test = mms(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN L-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    S = 1 / (1 + np.exp(-Z))\n",
    "    return S,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivade_sigmoid(z):\n",
    "    gz,z = sigmoid(z) \n",
    "    return gz * (1-gz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network, (including input layer)\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.normal(0, 1, (layer_dims[l], layer_dims[l-1]))\n",
    "        parameters['b' + str(l)] = np.random.random((layer_dims[l], 1))\n",
    "      \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks (not input layer including)\n",
    "    v = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l+1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l+1)])\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation in L - Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W,A)+b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache) #linear_cahce: A_prev,Wi,bi - activation_cache: Zi\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X,Y,parameters,pred=False):\n",
    "    caches = []\n",
    "    A = X                                     #(input size, number of examples)\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network (not input layer including)\n",
    "    \n",
    "    # Implement [LINEAR -> SIGMOID]*(L-1). To L-1 Layers\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        W=parameters['W' + str(l)]\n",
    "        b=parameters['b' + str(l)]\n",
    "        A, cache = linear_activation_forward(A_prev, W, b, \"sigmoid\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Last layer\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    # Predicction\n",
    "    if pred:\n",
    "        # The max value is 1 , else 0\n",
    "        AL_temp = AL.T\n",
    "        Y_prediction = np.zeros_like(AL_temp)\n",
    "        Y_prediction[np.arange(len(AL_temp)), AL_temp.argmax(1)] = 1\n",
    "        Y_prediction = Y_prediction.T\n",
    "        return Y_prediction\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(AL) + (1 - Y) * (np.log(1 - AL)))\n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Propagation in L - Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m) * np.dot(dZ,A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        dZ = dA * derivade_sigmoid(activation_cache) # activation_cache = Z ; dA = np.dot(W.T,dZ) excep the first dA\n",
    "    \n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers (not input layer including)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL =- (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, \n",
    "                                                                                                  current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (SIGMOID -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 2)], caches\". Outputs: \"grads[\"dA\" + str(l + 1)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev, dW, db = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, \"sigmoid\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev\n",
    "        grads[\"dW\" + str(l + 1)] = dW\n",
    "        grads[\"db\" + str(l + 1)] = db\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 # number of layers in the neural network (not input layer including)\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\" + str(l+1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Parameters with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_momentum(parameters, grads, v, learning_rate, beta):\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks (not input layer including)\n",
    "    \n",
    "    # Momentum update for each parameter\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = beta * v[\"dW\" + str(l + 1)] + (1 - beta) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta * v[\"db\" + str(l + 1)] + (1 - beta) * grads['db' + str(l + 1)]\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L - layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, X_test, Y_test, layers_dims, learning_rate, num_iterations, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []                         \n",
    "    \n",
    "    # Parameters initialization.\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    #Velocity initialization.\n",
    "    v = initialize_velocity(parameters)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> SIGMOID]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X,Y,parameters,pred=False)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters. #Esto tem que quedar comentado si vc vai usar com Momemtum\n",
    "        #parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        # Update parameters with Momentum.\n",
    "        parameters, v = update_parameters_with_momentum(parameters, grads, v, learning_rate, beta = 0.9)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 500 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 500 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # Train Predicction\n",
    "    Y_prediction =  L_model_forward(X,Y,parameters,pred=True)\n",
    "    print(\"------------------\")\n",
    "    print(\"Train Prediccion:\")\n",
    "    print(Y_prediction.shape)\n",
    "    print(Y_prediction)\n",
    "    print(\"Train Accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction - Y)) * 100))\n",
    "    print(\"Train F1 Score: \",f1_score(Y, Y_prediction, average='macro')*100)  \n",
    "    \n",
    "    # Test Predicction\n",
    "    print(\"------------------\")\n",
    "    Y_prediction =  L_model_forward(X_test,Y_test,parameters,pred=True)\n",
    "    print(\"Test Prediccion:\")\n",
    "    print(Y_prediction.shape)\n",
    "    print(Y_prediction)\n",
    "    print(\"Test Accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction - Y_test)) * 100))\n",
    "    print(\"Test F1 Score: \",f1_score(Y_test, Y_prediction, average='macro')*100)  \n",
    "\n",
    "\n",
    "\n",
    "    if np.array_equal(Y,Y_prediction):\n",
    "        print(\"Success Prediction\")\n",
    "    else:\n",
    "        print(\"Un - success Prediction\")\n",
    "        \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "            \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1199)\n",
      "(3, 1199)\n",
      "Cost after iteration 0: 1.961247\n",
      "Cost after iteration 500: 0.845918\n",
      "------------------\n",
      "Train Prediccion:\n",
      "(3, 1199)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Train Accuracy: 89.26883514039477 %\n",
      "Train F1 Score:  83.90325271059216\n",
      "------------------\n",
      "Test Prediccion:\n",
      "(3, 400)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Test Accuracy: 88.66666666666667 %\n",
      "Test F1 Score:  83.0\n",
      "Un - success Prediction\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y = x_train.T , y_train.T\n",
    "X_test, Y_test = x_test.T, y_test.T \n",
    "#print(X)\n",
    "#print(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "layers_dims = [11, 9, 7, 5 ,3] #  2-layer model\n",
    "parameters = L_layer_model(X, Y, X_test, Y_test,layers_dims, learning_rate = 0.5, num_iterations = 1000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
