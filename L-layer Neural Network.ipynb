{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    S = 1 / (1 + np.exp(-Z))\n",
    "    return S,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivade_sigmoid(z):\n",
    "    gz,z = sigmoid(z) \n",
    "    return gz * (1-gz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network, (including input layer)\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.normal(0, 1, (layer_dims[l], layer_dims[l-1]))\n",
    "        parameters['b' + str(l)] = np.random.random((layer_dims[l], 1))\n",
    "      \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks (not input layer including)\n",
    "    v = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l+1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l+1)])\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation in L - Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W,A)+b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache) #linear_cahce: A_prev,Wi,bi - activation_cache: Zi\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X,Y,parameters,pred=False):\n",
    "    caches = []\n",
    "    A = X                                     #(input size, number of examples)\n",
    "    L = len(parameters) // 2              # number of layers in the neural network (not input layer including)\n",
    "    \n",
    "    # Implement [LINEAR -> SIGMOID]*(L-1). To L-1 Layers\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        W=parameters['W' + str(l)]\n",
    "        b=parameters['b' + str(l)]\n",
    "        A, cache = linear_activation_forward(A_prev, W, b, \"sigmoid\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Last layer\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    # Predicction\n",
    "    if pred:\n",
    "        Y_prediction = np.zeros((Y.shape[0], Y.shape[1]))\n",
    "        for i in range(AL.shape[0]):\n",
    "            # Convert probabilities a[0,i] to actual predictions p[0,i]\n",
    "            for j in range(AL.shape[1]):\n",
    "                Y_prediction[i, j] = 1 if AL[i, j] >= 0.5 else 0\n",
    "        return Y_prediction\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(AL) + (1 - Y) * (np.log(1 - AL)))\n",
    "    #cost = (-1 / m)  * np.sum(np.multiply(Y, np.log(AL)) + np.multiply(1 - Y, np.log(1 - AL)))\n",
    "    #cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Propagation in L - Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m) * np.dot(dZ,A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        dZ = dA * derivade_sigmoid(activation_cache) # activation_cache = Z ; dA = np.dot(W.T,dZ) excep the first dA\n",
    "    \n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers (not input layer including)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL =- (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, \n",
    "                                                                                                  current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (SIGMOID -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 2)], caches\". Outputs: \"grads[\"dA\" + str(l + 1)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev, dW, db = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, \"sigmoid\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev\n",
    "        grads[\"dW\" + str(l + 1)] = dW\n",
    "        grads[\"db\" + str(l + 1)] = db\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 # number of layers in the neural network (not input layer including)\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] =parameters[\"W\" + str(l+1)]-learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] =parameters[\"b\" + str(l+1)]-learning_rate*grads[\"db\" + str(l+1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Parameters with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_momentum(parameters, grads, v, learning_rate, beta):\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks (not input layer including)\n",
    "    \n",
    "    # Momentum update for each parameter\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = beta * v[\"dW\" + str(l + 1)] + (1 - beta) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta * v[\"db\" + str(l + 1)] + (1 - beta) * grads['db' + str(l + 1)]\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L - layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.5, num_iterations = 3000, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []                         \n",
    "    \n",
    "    # Parameters initialization.\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    #Velocity initialization.\n",
    "    v = initialize_velocity(parameters)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> SIGMOID]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X,Y,parameters,pred=False)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        #parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        # Update parameters with Momentum.\n",
    "        parameters, v = update_parameters_with_momentum(parameters, grads, v, learning_rate, beta = 0.9)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # Predicction\n",
    "    Y_prediction =  L_model_forward(X,Y,parameters,pred=True)\n",
    "    print(\"------------------\")\n",
    "    print(\"Prediccion:\")\n",
    "    print(Y_prediction)\n",
    "    if np.array_equal(Y,Y_prediction):\n",
    "        print(\"Success Prediction\")\n",
    "    else:\n",
    "        print(\"Un - success Prediction\")\n",
    "        \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "            \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15)\n",
      "(15, 15)\n",
      "Cost after iteration 0: 17.977078\n",
      "Cost after iteration 100: 3.368677\n",
      "Cost after iteration 200: 3.001658\n",
      "Cost after iteration 300: 2.714420\n",
      "Cost after iteration 400: 2.439309\n",
      "Cost after iteration 500: 2.191273\n",
      "Cost after iteration 600: 1.993661\n",
      "Cost after iteration 700: 1.838761\n",
      "Cost after iteration 800: 1.711590\n",
      "Cost after iteration 900: 1.602278\n",
      "Cost after iteration 1000: 1.504431\n",
      "Cost after iteration 1100: 1.412756\n",
      "Cost after iteration 1200: 1.325053\n",
      "Cost after iteration 1300: 1.240059\n",
      "Cost after iteration 1400: 1.151772\n",
      "Cost after iteration 1500: 1.056504\n",
      "Cost after iteration 1600: 0.969122\n",
      "Cost after iteration 1700: 0.897047\n",
      "Cost after iteration 1800: 0.836931\n",
      "Cost after iteration 1900: 0.785886\n",
      "Cost after iteration 2000: 0.741963\n",
      "Cost after iteration 2100: 0.703737\n",
      "Cost after iteration 2200: 0.670108\n",
      "Cost after iteration 2300: 0.640202\n",
      "Cost after iteration 2400: 0.613304\n",
      "Cost after iteration 2500: 0.588827\n",
      "Cost after iteration 2600: 0.566287\n",
      "Cost after iteration 2700: 0.545297\n",
      "Cost after iteration 2800: 0.525557\n",
      "Cost after iteration 2900: 0.506850\n",
      "------------------\n",
      "Prediccion:\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Un - success Prediction\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5xcdX3/8dd7d2Yvye5sErK5QRJQI4hWUCNqvRRRKVDqrWpJtV7a3y/iT369P1rrrw+1F38Pf7XaarEiVkQfVdRWEUSqIq0CKkLAhEu4BIGQsCS7SUh2N8leZvfz++Oc3Z1MZiaTy+zs7ryfj8c8zplzm+/JwLz3fL/nfL+KCMzMzMppqncBzMxsZnNQmJlZRQ4KMzOryEFhZmYVOSjMzKwiB4WZmVXkoDArIOk/Jb2r3uUwm0kcFDYjSHpc0mvrXY6IuDAivlTvcgBI+pGk/zENn9Mq6SpJ/ZJ2SPqTCtueK2lc0mDBy8E6x2XqXQCz6SIpExH5epcDZlZZgI8Aa4DVwDLgvyVtjojvldm+JyJOma7CWf35isJmPEkXS9ooaa+kn0p6fsG6D0j6paQBSZslvalg3bsl/UTSP0raA3wkXXabpH+Q9LSkxyRdWLDP5F/xVWx7mqRb0s/+oaTPSPq3MudwrqTtkv5C0g7gi5IWSrpBUl96/BsknZJu/1HglcDl6V/tl6fLz5B0k6Q9kh6S9LYT8E/8TuBvI+LpiHgA+Dzw7hNwXJsjHBQ2o0l6IXAV8F7gJOBzwPWSWtNNfknyg9oF/DXwb5KWFxziJcCjwBLgowXLHgIWA38PfEGSyhSh0rZfBe5Iy/UR4HePcDrLgEUkf7mvJ/n/74vp+1XAQeBygIj4P8CtwGUR0RERl0maD9yUfu4SYB3wL5KeW+rDJP1LGq6lXvek2ywEVgCbCnbdBJQ8ZmqJpJ1pcP5jWi6bwxwUNtP9T+BzEfHziBhL2w+GgZcCRMS/R0RPRIxHxNeBLcA5Bfv3RMQ/R0Q+Ig6my7ZGxOcjYgz4ErAcWFrm80tuK2kV8GLgQxExEhG3Adcf4VzGgQ9HxHBEHIyI3RHxzYg4EBEDJEH2axX2vxh4PCK+mJ7P3cA3gbeU2jgi/ldELCjzmrgq60in+wp23Qd0linDg8DZ6b/DecCLgE8e4bxtlnNQ2Ey3GvjTwr+GgZUkfwUj6Z0F1VJ7geeR/PU/YVuJY+6YmImIA+lsR4ntKm27AthTsKzcZxXqi4ihiTeS5kn6nKStkvqBW4AFkprL7L8aeEnRv8XbSa5UjtVgOs0VLMsBA6U2jogdEbE5DebHgD+nTFDZ3OGgsJluG/DRor+G50XENZJWk9SnXwacFBELgPuAwmqkWnWP/BSwSNK8gmUrj7BPcVn+FDgdeElE5IBXpctVZvttwI+L/i06IuJ9pT5M0hVFdycVvu4HiIin03M5q2DXs4D7j3AuhedUrtrO5ggHhc0kWUltBa8MSRBcKuklSsyX9BuSOoH5JD9UfQCS3kNyRVFzEbEV2EDSQN4i6WXAbx7lYTpJ2iX2SloEfLho/U7gGQXvbwCeLel3JWXT14slPadMGS9Ng6TUq7AN4svAX6WN62eQVPddXeqYaaP8qvS7WAl8DLjuKM/bZhkHhc0kN5L8cE68PhIRG0h+uC4HngYeIb0jJyI2A58Afkbyo/orwE+msbxvB14G7Ab+Dvg6SftJtf4JaAd2AbcDxbejfgp4S3pH1KfTdozzgUuAHpJqsf8HtHJ8PkxyU8BW4MfAxwtvjU2vQF6Zvn0hyb/3fuCnJFdwf3Ccn28znDxwkdmJIenrwIMRUXxlYDar+YrC7Bil1T7PlNQk6QLgDcC3610usxPNT2abHbtlwLdInqPYDrwvIn5R3yKZnXiuejIzs4pc9WRmZhXNqaqnxYsXx6mnnlrvYpiZzRp33XXXrojorrTNnAqKU089lQ0bNtS7GGZms4akrUfaxlVPZmZWkYPCzMwqclCYmVlFDgozM6vIQWFmZhU5KMzMrCIHhZmZVdTwQRERfPrmLfz44b56F8XMbEZq+KCQxJW3PMqPHuqtd1HMzGakhg8KgFxbhv6D+XoXw8xsRqpZFx6SrgIuBnoj4nnpsq+TjBEMsADYGxFnl9j3cZLB3ceAfESsrVU5AXLtWfqHRmv5EWZms1Yt+3q6mmT4yi9PLIiI356Yl/QJYF+F/V8dEbtqVroCufYs/QcdFGZmpdSs6ikibgH2lFonScDbgGtq9flHI9eWZZ+DwsyspHq1UbwS2BkRW8qsD+AHku6StL7Whcm1ZxgYchuFmVkp9epmfB2VryZeHhE9kpYAN0l6ML1COUwaJOsBVq1adUyFybW56snMrJxpv6KQlAHeDHy93DYR0ZNOe4FrgXMqbHtlRKyNiLXd3RXH3iirqz3LwHCesXEPC2tmVqweVU+vBR6MiO2lVkqaL6lzYh44H7ivlgXKtWcBGPCdT2Zmh6lZUEi6BvgZcLqk7ZJ+P111CUXVTpJWSLoxfbsUuE3SJuAO4LsR8b1alROS5ygAP0thZlZCzdooImJdmeXvLrGsB7gonX8UOKtW5Spl4orCz1KYmR3OT2aTtFEAbtA2MyvBQUFy1xPgZynMzEpwUJA8RwGuejIzK8VBQWHVkxuzzcyKOSiA+S0ZmuSqJzOzUhwUQFOT6GxzD7JmZqU4KFK59ozvejIzK8FBkepqz9LvjgHNzA7joEi5q3Ezs9IcFCn3IGtmVpqDIpVrz7gx28ysBAdFqqs96+cozMxKcFCkcm1ZDo6OMZIfr3dRzMxmFAdFyj3ImpmV5qBITfb35AZtM7NDOChSk/09+VkKM7NDOChS7mrczKw0B0Uq58GLzMxKclCkJq4o3JhtZnYoB0XKY1KYmZVWs6CQdJWkXkn3FSz7iKQnJW1MXxeV2fcCSQ9JekTSB2pVxkJt2SayzXIbhZlZkVpeUVwNXFBi+T9GxNnp68bilZKagc8AFwJnAusknVnDck58btLfk6uezMwOUbOgiIhbgD3HsOs5wCMR8WhEjABfA95wQgtXRq7dHQOamRWrRxvFZZLuSaumFpZYfzKwreD99nRZSZLWS9ogaUNfX99xFSznMSnMzA4z3UHxWeCZwNnAU8AnSmyjEsui3AEj4sqIWBsRa7u7u4+rcLm2jNsozMyKTGtQRMTOiBiLiHHg8yTVTMW2AysL3p8C9ExH+XLtWQYcFGZmh5jWoJC0vODtm4D7Smx2J7BG0mmSWoBLgOuno3xuzDYzO1ymVgeWdA1wLrBY0nbgw8C5ks4mqUp6HHhvuu0K4F8j4qKIyEu6DPg+0AxcFRH316qchSbGpIgIpFI1YGZmjadmQRER60os/kKZbXuAiwre3wgcdutsreXaM4yMjTM0Ok57S/N0f7yZ2YzkJ7MLuBsPM7PDOSgKuGNAM7PDOSgKdHmUOzOzwzgoCuTakiYbP0thZjbFQVEg5x5kzcwO46Ao4MZsM7PDOSgK5NqTqic3ZpuZTXFQFGjNNNOWbXIbhZlZAQdFkVxb1m0UZmYFHBRFkq7GfUVhZjbBQVGky0FhZnYIB0URj0lhZnYoB0WRXLvbKMzMCjkoinhMCjOzQzkoiiRjUowSUXb0VTOzhuKgKJJrzzAeMDjs6iczM3BQHGaqGw8HhZkZOCgO4zEpzMwO5aAo0uWgMDM7RM2CQtJVknol3Vew7OOSHpR0j6RrJS0os+/jku6VtFHShlqVsZSJqic/S2FmlqjlFcXVwAVFy24CnhcRzwceBv6ywv6vjoizI2JtjcpX0mQPsm6jMDMDahgUEXELsKdo2Q8iYuIX+HbglFp9/rGabMz2FYWZGVDfNorfA/6zzLoAfiDpLknrKx1E0npJGyRt6OvrO+5CdbZNXFE4KMzMoE5BIen/AHngK2U2eXlEvBC4EHi/pFeVO1ZEXBkRayNibXd393GXLdPcREer+3syM5sw7UEh6V3AxcDbo8zjzxHRk057gWuBc6avhEnHgO7vycwsMa1BIekC4C+A10fEgTLbzJfUOTEPnA/cV2rbWvGYFGZmU2p5e+w1wM+A0yVtl/T7wOVAJ3BTeuvrFem2KyTdmO66FLhN0ibgDuC7EfG9WpWzlFza35OZmUGmVgeOiHUlFn+hzLY9wEXp/KPAWbUqVzVybVm2P13ygsfMrOH4yewScu0ZBvwchZkZ4KAoqctVT2ZmkxwUJeTasgwM5xkb95gUZmYOihImepAd8J1PZmYOilJyE09n+1kKMzMHRSmTXY37isLMzEFRigcvMjOb4qAowWNSmJlNcVCUMDUmhYPCzMxBUcLUcKhuzDYzc1CUML8lQ5N8RWFmBg6KkpqaRGdb1m0UZmY4KMrKtWd815OZGQ6Ksrras/S7Y0AzMwdFOTlXPZmZAQ6KsnJt7kHWzAwcFGXl2jO+68nMDAdFWcmYFG6jMDNzUJSRa8tycHSMkfx4vYtiZlZXNQsKSVdJ6pV0X8GyRZJukrQlnS4ss+8Fkh6S9IikD9SqjJXk3IOsmRlQ2yuKq4ELipZ9ALg5ItYAN6fvDyGpGfgMcCFwJrBO0pk1LGdJk/09uUHbzBpczYIiIm4B9hQtfgPwpXT+S8AbS+x6DvBIRDwaESPA19L9ptXUmBRupzCzxjbdbRRLI+IpgHS6pMQ2JwPbCt5vT5dNK3c1bmaWqCooJL21mmUniEosi7IbS+slbZC0oa+v74QVwoMXmZklqr2i+Msqlx3JTknLAdJpb4lttgMrC96fAvSUO2BEXBkRayNibXd39zEUqbSJKwo3ZptZo8tUWinpQuAi4GRJny5YlQOOpfL+euBdwMfS6XUltrkTWCPpNOBJ4BLgd47hs46Lx6QwM0sc6YqiB9gADAF3FbyuB3690o6SrgF+Bpwuabuk3ycJiNdJ2gK8Ln2PpBWSbgSIiDxwGfB94AHgGxFx/7Gd3rFryzaRbZbbKMys4VW8ooiITcAmSV+NiFGA9NmHlRHx9BH2XVdm1WtKbNtDcuUy8f5G4MYjlL2mJCX9PbnqycwaXLVtFDdJyklaBGwCvijpkzUs14yQa3fHgGZm1QZFV0T0A28GvhgRLwJeW7tizQw5j0lhZlZ1UGTSu5TeBtxQw/LMKLm2jNsozKzhVRsUf0PSuPzLiLhT0jOALbUr1syQa88y4KAwswZXsTF7QkT8O/DvBe8fBX6rVoWaKdyYbWZW/ZPZp0i6Nu0Ndqekb0o6pdaFq7eJMSkiyj4YbmY251Vb9fRFkmcnVpD0u/SddNmclmvPMDI2ztCox6Qws8ZVbVB0R8QXIyKfvq4GTlx/GTOUu/EwM6s+KHZJeoek5vT1DmB3LQs2E7hjQDOz6oPi90hujd0BPAW8BXhPrQo1U3R5lDszs+ruegL+FnjXRLcd6RPa/0ASIHNWri355/GzFGbWyKq9onh+Yd9OEbEHeEFtijRz5NyDrJlZ1UHRlHYGCExeUVR7NTJruTHbzKz6H/tPAD+V9B8ko829DfhozUo1Q+Tak38eN2abWSOr9snsL0vaAJxHMlTpmyNic01LNgO0Zpppyza5jcLMGlrV1UdpMMz5cCiWa8u6jcLMGlq1bRQNq6vd/T2ZWWNzUBxBzkFhZg3OQXEEHpPCzBqdg+IIcu1uozCzxjbtQSHpdEkbC179kv6oaJtzJe0r2OZD013OCW6jMLNGN+0PzUXEQ8DZAJKagSeBa0tsemtEXDydZSsluetplIhAUr2LY2Y27epd9fQakuFVt9a5HGXl2jOMBwwOu/rJzBpTvYPiEuCaMuteJmmTpP+U9NxyB5C0XtIGSRv6+vpOeAGnuvFwUJhZY6pbUEhqAV5PwVjcBe4GVkfEWcA/A98ud5yIuDIi1kbE2u7uEz+WUpfHpDCzBlfPK4oLgbsjYmfxiojoj4jBdP5GICtp8XQXEDx4kZlZPYNiHWWqnSQtU9pyLOkcknLWZUS9iaonP0thZo2qLl2FS5oHvA54b8GySwEi4gqSEfTeJykPHAQuiYioR1kne5B1G4WZNai6BEVEHABOKlp2RcH85cDl012uUtxGYWaNrt53Pc14Ha0TVxQOCjNrTA6KI8g0N9HR6v6ezKxxOSiqkGvLuL8nM2tYDooquKtxM2tkDooqJD3IOijMrDE5KKqQa8u6jcLMGpaDogq59gwDfo7CzBqUg6IKXa56MrMG5qCoQq4ty8BwnrHxujwcbmZWVw6KKkx0DDjgO5/MrAE5KKqQa0ufzvazFGbWgBwUVZjs78lXFGbWgBwUVfCYFGbWyBwUVfCYFGbWyBwUVZgak8JBYWaNx0FRhakxKdyYbWaNx0FRhfktGZrkKwoza0wOiio0NYlO9/dkZg3KQVGlXHvGdz2ZWUOqS1BIelzSvZI2StpQYr0kfVrSI5LukfTCepSzUFd7ln53DGhmDShTx89+dUTsKrPuQmBN+noJ8Nl0Wje5NncMaGaNaaZWPb0B+HIkbgcWSFpezwJ5TAoza1T1CooAfiDpLknrS6w/GdhW8H57uuwwktZL2iBpQ19fXw2Kmsi1Z3zXk5k1pHoFxcsj4oUkVUzvl/SqovUqsU/JPr4j4sqIWBsRa7u7u090OSclY1K4jcLMGk9dgiIietJpL3AtcE7RJtuBlQXvTwF6pqd0peXashwcHWMkP17PYpiZTbtpDwpJ8yV1TswD5wP3FW12PfDO9O6nlwL7IuKpaS7qIXLuQdbMGlQ97npaClwraeLzvxoR35N0KUBEXAHcCFwEPAIcAN5Th3IeYrK/p4OjLO5orXNpzMymz7QHRUQ8CpxVYvkVBfMBvH86y3UkU2NSuJ3CzBrLTL09dsZxV+Nm1qgcFFXy4EVm1qgcFFWauKJwY7aZNRoHRZU8JoWZNSoHRZXask1km+U2CjNrOA6KKklKOgZ01ZOZNRgHxVFIuvFwUJhZY3FQHIVOj0lhZg3IQXEUcm0Zt1GYWcNxUByFXHuWAQeFmTUYB8VRSIZDdVCYWWNxUByFZDjUPElXVGZmjcFBcRQWd7QwMjbO6y//CV/9+RMMDrth28zmvnp0Mz5rveOlq2luEl+7YxsfvPZe/u67m/nN569g3UtWcdYpXaRdp5uZzSmaS9Uoa9eujQ0bNtT8cyKCX2zby9fueILvbHqKg6NjnLGsk3XnrOKNLzh5srsPM7OZTtJdEbG24jYOiuMzMDTKdRt7+NqdT3Dfk/20ZZu46FeWs+6cVaxdvdBXGWY2ozkoptl9T+7jmjue4LqNPQwO5zl5QTuvO3Mp55+5lBeftohss5uEzGxmcVDUyYGRPDfeu4Pv3beDW7f0MZwfJ9eW4bwzlnD+c5fxqmd309Hq5iEzqz8HxQxwYCTPrVt2cdPmndz8wE6ePjBKS3MTv/qsk3jdmUt53XOWsiTXVu9imlmDmpFBIWkl8GVgGTAOXBkRnyra5lzgOuCxdNG3IuJvjnTsmRgUhfJj49y19Wlu2ryTH2zeyRN7DgBw1soFvPaMJZz3nCWcuTzndg0zmzYzNSiWA8sj4m5JncBdwBsjYnPBNucCfxYRFx/NsWd6UBSKCB7eOchNm3dw0+adbNq+D4BluTbOe84SXnPGEn71mYtpb2muc0nNbC6rJiimvaI8Ip4CnkrnByQ9AJwMbK644xwjidOXdXL6sk4uO28NvQND/OihPv7rgV6u+8WTfPXnT9CaaeLlz1rMeWcs4bwzlrBiQXu9i21mDaiubRSSTgVuAZ4XEf0Fy88FvglsB3pIri7uL3OM9cB6gFWrVr1o69attS30NBjOj3HHY3u4+YFe/uvB3skqqjOWdfJrp3fzymd1s/bUhbRlfbVhZsdnRlY9TX6w1AH8GPhoRHyraF0OGI+IQUkXAZ+KiDVHOuZsqnqqVkTwy779/NeDO7n5gV7ufuJpRseC1kwTLz51ES9/1mJeuWYxZy7P0dTktg0zOzozNigkZYEbgO9HxCer2P5xYG1E7Kq03VwMimL7h/Pc8dgebntkF7dt2cVDOwcAWDgvy68+azGvSF8rF82rc0nNbDaYkW0USm7p+QLwQLmQkLQM2BkRIekcks4Ld09jMWes+a0ZXn3GEl59xhIAevuH+Mkvd3Hblt3c9kgf373nKQBWLmrnBSsXctbKBZy9cgHPXZFzVZWZHZN63PX0CuBW4F6S22MBPgisAoiIKyRdBrwPyAMHgT+JiJ8e6diNcEVRSVJNNchtW3bx88f2sHHbXp7aNwRApkk8Z3mOs1Z2cfbKhZy9sotnLO5wdZVZg5uxVU+10uhBUcrO/iE2btvLpm172bhtL/ds3zfZPXpna4bnr+zizOU51izpZM3SDtYs7fRT42YNxEFhhxkbDx7tG+QXBeGxpXeQkfz45DYnL2hPQmNJEhzPXtrJmiUdzHeAmM05M7KNwuqruUmsWdrJmqWdvG3tSiAJjyf2HODhnQM80jvIwzsHeHjnID/95e5DAmRFVxurT5rP6pPmseqkeaxeNDWfa3PX6mZzlYPCaG4Spy2ez2mL5/Prz51aXhwgv+wdZOueA/zwgV52DQ4fcoyF87KsOmk+qxfNY/VJ8zhlYTsrFiSvkxe0uyHdbBZzUFhZ5QIEYHA4zxO7D/DEnv1s3X2ArXsO8MTuA/xi29PccE8P40U1mifNb0mDo42TF8xLp+0sX9DOslwb3Z2tNLth3WxGclDYMelozXDmihxnrsgdtm50bJwd+4bo2XuQnn0H6dk7xPanD9Kz9yCP9u3n1i27ODAydsg+TYLuzlaW5dpYmmtjWVc6LZhfmmulozXjThPNppmDwk64bHMTKxfNK/vQX0TQfzDPk3uT8NjRP8TO/iF27BtiR/8Qj+/ez+2P7qZ/KH/YvvNamlnS2cqSzja6c60s7WxjSa51ctnSXDLNtTtQzE4UB4VNO0l0zcvSNS9b8opkwoGRPDv7h9mxLwmSnf1D9A4MT0439/Tz3/29h12dALQ0N9Hd2XroqyOZLilYtrij1e0nZkfgoLAZa15LhtMWZzht8fyK2w0O5+ntH2Jn/zC9A0P0DQxPvQaH2bbnAHdtfZo9+0dK7t/ZlpkMjcJAWdzRcsjyxR2tHs7WGpKDwma9jtYMHd0dPKO7o+J2o2Pj7B4cSQNkiN7+YXYNJoGyK13+QE8/twwOM1Ci2gtg0fyWklcmE68lna0sybXR6bYUm0McFNYwss1NLOtKGsehq+K2Q6Njh4RI78AQuwZGJq9YegeGeWzXfvoGhw951mRCe7aZpbnWtBG+rWh+6r2rvWw2cFCYldCWbeaUhfM4ZWHlXngnGuYnrlB6B5Lqr539w+zoH6I37UJlR/9QyUCZqPaauEo5vD0luXV44bwsGVd7WZ04KMyOQ2HD/LOWdJbdLiLYd3CUnf1JY/xEiExUefUNDHN/Tz99A8OTfXEV62rPsmh+CwvnJdMF81rS9y0smp9l4bwWFs5voas9S64tS1d7lrZsk6vA7Lg5KMymgSQWzEt+3E9fVj5QIBlzZKLaa6JBfs/+EZ7eP8KeA6M8vX+Enr1D3N/Tz+79IyWvVCa0NDeRa8+QKwiPXHuWrvYMnW1ZOlozdLZlknae1mTZ5Pt02ppx2DQ6B4XZDDO/NcP81gyrT6p8txckVyoHR8fYs3+EvQdG2bN/hP6hUfYdHKX/YD6ZTr4fZe+BEZ7Yc4B9B0cZGBpldOzInYJmm8W8lgzzW5qZ15pOWzLMb52azm/JMK+lmfaJabaZ9nQ6r6WZtpbmw5a3ZZt9F9ks4aAwm8Wk5Ed8XkuGUxYe/f7D+TEGhvIMDuUZHM4n88N5BodHGRzKMzCcrDswMsb+4XQ6kufA8BhP7RuaXL5/OM+B0TGOtjPq5ialodFEayYJkbZsE23pfGtmal1rtonWTBNt2WZaM+myTBOt6fYtmWR9S7pu4n2pZS2ZJjJN8pVSlRwUZg2sNdNMa0cziztaj/tYEcHQ6DgHR8c4MJJnaHSMAyNjHBwZ48BoMp2YHxoZY2h0jIOjYwyNjjOUT5flk/cHR8YYHM7TNzDMyNg4w6PjDOfH0uk4I2Plq9uqJSV3wrU2J8GRTactmSZampvIZpJ12YyS9+myZF5T+0ysK9o206yi9ZrcLjM5f+g009xEtklF2zTVvR80B4WZnRCSkmqllmYWzW+p6WeNjwfD+TQ88kmQDOXHGMmPTy4fyY9Pvp+ajk2+Hx0bZ3hsfHK70Yn5yWkwkgbXwFB+apuxcUbzMTWfbl/cEeaJJEG2KQmPTIkg6e5o5RuXvqxmn++gMLNZp6lpKpRmirHxJDySV0wGSH58an5iXT4NmfxYkB9PQilftG9+LBgdT6cF+00cb3L5eNDRWtt/BweFmdkJ0Nwkmpua5+RDlHW55UDSBZIekvSIpA+UWC9Jn07X3yPphfUop5mZ1SEoJDUDnwEuBM4E1kk6s2izC4E16Ws98NlpLaSZmU2qxxXFOcAjEfFoRIwAXwPeULTNG4AvR+J2YIGk5dNdUDMzq09QnAxsK3i/PV12tNuYmdk0qEdQlLohuPjGsmq2STaU1kvaIGlDX1/fcRfOzMwOVY+g2A6sLHh/CtBzDNsAEBFXRsTaiFjb3d19QgtqZmb1CYo7gTWSTpPUAlwCXF+0zfXAO9O7n14K7IuIp6a7oGZmVofnKCIiL+ky4PtAM3BVRNwv6dJ0/RXAjcBFwCPAAeA9011OMzNLKI62F68ZTFIfsPUYd18M7DqBxam3uXY+MPfOaa6dD8y9c5pr5wOHn9PqiKhYbz+nguJ4SNoQEWvrXY4TZa6dD8y9c5pr5wNz75zm2vnAsZ2TO4M3M7OKHBRmZlaRg2LKlfUuwAk2184H5t45zbXzgbl3TnPtfOAYzsltFGZmVpGvKMzMrCIHhZmZVdTwQXGksTFmI0mPS7pX0kZJG+pdnqMl6SpJvZLuK1i2SNJNkrak04X1LOPRKnNOH5H0ZPo9bZR0UT3LeDQkrZT035IekHS/pD9Ml8/a76nCOc3K70lSm6Q7JG1Kz+ev0+VH/R01dBtFOjbGw8DrSPqXuhNYFxGb61qw4yTpcWBtRMzKB4UkvQoYJOlq/nnpsr8H9kTEx9JAXxgRf1HPch6NMuf0EWAwIv6hnmU7Fu2zXmEAAAYiSURBVGm3/8sj4m5JncBdwBuBdzNLv6cK5/Q2ZuH3JEnA/IgYlJQFbgP+EHgzR/kdNfoVRTVjY9g0i4hbgD1Fi98AfCmd/xLJ/8CzRplzmrUi4qmIuDudHwAeIBkKYNZ+TxXOaVZKx/MZTN9m01dwDN9RowfFXB33IoAfSLpL0vp6F+YEWTrRMWQ6XVLn8pwol6XD/V41m6ppCkk6FXgB8HPmyPdUdE4wS78nSc2SNgK9wE0RcUzfUaMHRdXjXswyL4+IF5IMKfv+tNrDZp7PAs8EzgaeAj5R3+IcPUkdwDeBP4qI/nqX50QocU6z9nuKiLGIOJtkqIZzJD3vWI7T6EFR9bgXs0lE9KTTXuBakiq22W7nxHC46bS3zuU5bhGxM/0feRz4PLPse0rrvb8JfCUivpUuntXfU6lzmu3fE0BE7AV+BFzAMXxHjR4U1YyNMatImp82xCFpPnA+cF/lvWaF64F3pfPvAq6rY1lOiKJx4N/ELPqe0obSLwAPRMQnC1bN2u+p3DnN1u9JUrekBel8O/Ba4EGO4Ttq6LueANJb3f6JqbExPlrnIh0XSc8guYqAZLyRr862c5J0DXAuSXfIO4EPA98GvgGsAp4A3hoRs6ZxuMw5nUtSnRHA48B7Z8sAXZJeAdwK3AuMp4s/SFKnPyu/pwrntI5Z+D1Jej5JY3UzyUXBNyLibySdxFF+Rw0fFGZmVlmjVz2ZmdkROCjMzKwiB4WZmVXkoDAzs4ocFGZmVpGDwmY8ST9Np6dK+p0TfOwPlvqsWpH0RkkfqtGxP3jkrY76mL8i6eoTfVybXXx7rM0aks4F/iwiLj6KfZojYqzC+sGI6DgR5auyPD8FXn+8PfuWOq9anYukHwK/FxFPnOhj2+zgKwqb8SRN9ID5MeCV6ZgAf5x2ePZxSXemHba9N93+3HRcga+SPDyFpG+nnSTeP9FRoqSPAe3p8b5S+FlKfFzSfUrG9vjtgmP/SNJ/SHpQ0lfSJ3qR9DFJm9OyHNYltaRnA8MTISHpaklXSLpV0sOSLk6XV31eBccudS7vUDIewUZJn1PSrT6SBiV9VMk4BbdLWpouf2t6vpsk3VJw+O+Q9FpgjSoi/PJrRr9IxgKA5EnmGwqWrwf+Kp1vBTYAp6Xb7QdOK9h2UTptJ+mC4aTCY5f4rN8CbiJ5qnUpyROsy9Nj7yPpF6wJ+BnwCmAR8BBTV+kLSpzHe4BPFLy/Gvheepw1JH2PtR3NeZUqezr/HJIf+Gz6/l+Ad6bzAfxmOv/3BZ91L3BycfmBlwPfqfd/B37V75WpNlDMZqDzgedLekv6vovkB3cEuCMiHivY9g8kvSmdX5lut7vCsV8BXBNJ9c5OST8GXgz0p8feDpB24XwqcDswBPyrpO8CN5Q45nKgr2jZNyLpbG6LpEeBM47yvMp5DfAi4M70gqedqc7fRgrKdxfJwF0APwGulvQN4FtTh6IXWFHFZ9oc5aCw2UzA/46I7x+yMGnL2F/0/rXAyyLigKQfkfzlfqRjlzNcMD8GZCIiL+kckh/oS4DLgPOK9jtI8qNfqLiRMKjyvI5AwJci4i9LrBuNiInPHSP9HYiISyW9BPgNYKOksyNiN8m/1cEqP9fmILdR2GwyAHQWvP8+8L60a2gkPTvtMbdYF/B0GhJnAC8tWDc6sX+RW4DfTtsLuoFXAXeUK5iSMQy6IuJG4I9IOpEr9gDwrKJlb5XUJOmZwDNIqq+qPa9ihedyM/AWSUvSYyyStLrSzpKeGRE/j4gPAbuY6oL/2cySHlOtNnxFYbPJPUBe0iaS+v1PkVT73J02KPdReljH7wGXSrqH5If49oJ1VwL3SLo7It5esPxa4GXAJpK/8v88InakQVNKJ3CdpDaSv+b/uMQ2twCfkKSCv+gfAn5M0g5yaUQMSfrXKs+r2CHnIumvSEY6bAJGgfcDWyvs/3FJa9Ly35yeO8Crge9W8fk2R/n2WLNpJOlTJA3DP0yfT7ghIv6jzsUqS1IrSZC9IiLy9S6P1Yernsym1/8F5tW7EEdhFfABh0Rj8xWFmZlV5CsKMzOryEFhZmYVOSjMzKwiB4WZmVXkoDAzs4r+P3+0+iTWL+sGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.identity(15, dtype = float)\n",
    "X= X.T\n",
    "Y = X\n",
    "#print(X)\n",
    "#print(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "layers_dims = [15, 4, 15] #  2-layer model\n",
    "parameters = L_layer_model(X, Y, layers_dims, num_iterations = 3000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
