{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale as mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,name):\n",
    "    csv_path = os.path.join(path, name)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wine dataset ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>atr1</th>\n",
       "      <th>atr2</th>\n",
       "      <th>atr3</th>\n",
       "      <th>atr4</th>\n",
       "      <th>atr5</th>\n",
       "      <th>atr6</th>\n",
       "      <th>atr7</th>\n",
       "      <th>atr8</th>\n",
       "      <th>atr9</th>\n",
       "      <th>atr10</th>\n",
       "      <th>atr11</th>\n",
       "      <th>atr12</th>\n",
       "      <th>atr13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   atr1  atr2  atr3  atr4  atr5  atr6  atr7  atr8  atr9  atr10  atr11  \\\n",
       "0      1  14.23  1.71  2.43  15.6   127  2.80  3.06  0.28  2.29   5.64   1.04   \n",
       "1      1  13.20  1.78  2.14  11.2   100  2.65  2.76  0.26  1.28   4.38   1.05   \n",
       "2      1  13.16  2.36  2.67  18.6   101  2.80  3.24  0.30  2.81   5.68   1.03   \n",
       "3      1  14.37  1.95  2.50  16.8   113  3.85  3.49  0.24  2.18   7.80   0.86   \n",
       "4      1  13.24  2.59  2.87  21.0   118  2.80  2.69  0.39  1.82   4.32   1.04   \n",
       "\n",
       "   atr12  atr13  \n",
       "0   3.92   1065  \n",
       "1   3.40   1050  \n",
       "2   3.17   1185  \n",
       "3   3.45   1480  \n",
       "4   2.93    735  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"\"\n",
    "name = \"wine.data\"\n",
    "data = load_data(path,name)\n",
    "print(\"Loading wine dataset ...\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert Categorical Output to One Hot Vector\n",
      "(178, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Convert Categorical Output to One Hot Vector\")\n",
    "def categorical_output(): \n",
    "    Y = data[\"class\"]\n",
    "    Y = Y.values.reshape(-1,1)\n",
    "    enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "    enc.fit(Y)\n",
    "    Y = enc.transform(Y).toarray() #Converting in hot vectors\n",
    "    return Y\n",
    "Y = categorical_output()\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing inputs droping Labels and droping indexs\n",
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing inputs droping Labels and droping indexs\")\n",
    "def preprocessing_input():\n",
    "    X = data\n",
    "    X = X.drop(\"class\", axis = 1)\n",
    "    X = mms(X) #Scalling \n",
    "    return X\n",
    "X = preprocessing_input()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RBF Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing the center indexes:\n",
      "0 , 59\n",
      "59 , 130\n",
      "130 , 178\n"
     ]
    }
   ],
   "source": [
    "# Choosing  the centers as the media of each atribute\n",
    "def choosing_centers(X):\n",
    "    index = [] # Each center is a vector that works as a prototype of each class\n",
    "    labels = data[\"class\"]\n",
    "    pivote = labels[0]\n",
    "    centers = []\n",
    "    for row in range(0,len(labels)):\n",
    "        if labels[row] != pivote:\n",
    "            index.append(row)\n",
    "            pivote = labels[row]\n",
    "    index.append(len(labels))    \n",
    "    # Calculading the media of each class \n",
    "    tmp = 0\n",
    "    for i in index:\n",
    "        print(tmp,\",\",i)\n",
    "        center = X[tmp:i]\n",
    "        center = np.mean(center, axis=0)\n",
    "        center = np.reshape(center, (1,-1))\n",
    "        centers.append(center)\n",
    "        tmp = i     \n",
    "    return centers\n",
    "print('Choosing the center indexes:')\n",
    "centers = choosing_centers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(beta,X,center):\n",
    "    return np.exp(-beta*((np.linalg.norm(X-center,axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the phi(s) with respect each example:  (178, 3)\n"
     ]
    }
   ],
   "source": [
    "#Exist a phi p/c center, in this particular case there are three vectors as centers , then three phi's\n",
    "def RBF_act_fun(beta,X,centers):    \n",
    "    beta = 1 # Beta represents the amplitud of Gaussian function\n",
    "    phis = np.zeros((X.shape[0],1))\n",
    "    for center in centers:\n",
    "        phi = gaussian(1,X,center)\n",
    "        phi = np.reshape(phi, (-1,1))\n",
    "        phis = np.concatenate((phis,phi), axis=1) # We stack every phi column-vector in a matrix of phi's \n",
    "    phis =np.delete(phis, 0, 1)  # We delete unuseful column of 0's\n",
    "    return phis\n",
    "print('Calculating the phi(s) with respect each example: ',phis.shape)\n",
    "phis = RBF_act_fun(1,X,centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individuals Perceptrons: Output Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(n_y,n_x):\n",
    "    w = np.zeros(shape=(n_y, n_x))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_pred, Y):\n",
    "    contador = 0\n",
    "    Y_pred = Y_pred.T\n",
    "    Y = Y.T\n",
    "    for i in range(Y_pred.shape[0]) :\n",
    "        if np.array_equal(Y_pred[i],Y[i]):\n",
    "            contador +=1\n",
    "    accuracy = (contador*100.0)/Y_pred.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y, pred=False):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION \n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(Z)  \n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A)))  # compute cost based in sigmoid function\n",
    "    \n",
    "    # BACKWARD PROPAGATION \n",
    "    dw = (1 / m) * np.dot(X, (A - Y).T)\n",
    "    db = (1 / m) * np.sum(A - Y)\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    # Predicction\n",
    "    if pred:\n",
    "        # The max value is 1 , else 0\n",
    "        A_temp = A.T\n",
    "        Y_prediction = np.zeros_like(A_temp)\n",
    "        Y_prediction[np.arange(len(A_temp)), A_temp.argmax(1)] = 1 # Convert [0.9,0.2,0.05] en [1,0,0]\n",
    "        Y_prediction = Y_prediction.T\n",
    "        return Y_prediction\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):       \n",
    "        # Cost and gradient calculation \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        w = w - learning_rate * dw  # need to broadcast\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=1, learning_rate=0.5, print_cost=False):\n",
    "    \n",
    "    # Initialize parameters with zeros     \n",
    "    w, b = initialize_with_zeros(Y_train.shape[0],X_train.shape[0]) \n",
    "    \n",
    "    # Gradient descent \n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    #Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = propagate(w, b, X_train, Y_train, pred=True)\n",
    "    Y_prediction_test  = propagate(w, b, X_test, Y_test, pred=True)\n",
    "\n",
    "    # Print train/test Errors    \n",
    "    print(\"Train Accuracy: \",accuracy(Y_prediction_train, Y_train)) \n",
    "    print(\"Test  Accuracy: \",accuracy(Y_prediction_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  95.48872180451127\n",
      "Test  Accuracy:  95.55555555555556\n",
      "Los datos estan en Shuffle\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(phis, Y,\n",
    "                                                    stratify=Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)\n",
    "model(X_train.T, Y_train.T, X_test.T, Y_test.T, num_iterations=100, learning_rate=0.59)\n",
    "print(\"Los datos estan en Shuffle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
